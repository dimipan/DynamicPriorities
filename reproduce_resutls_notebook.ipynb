{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49cffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from agents import QLearningAgentFlat, QLearningAgentMaxInfoRL\n",
    "from robot_utils import RunningParameters\n",
    "param = RunningParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a258f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define environment configurations\n",
    "env_configs = [\n",
    "    # Config 1 (Original)\n",
    "    {\n",
    "        'init_positions': [[2, 1]],\n",
    "        'target_pos': [0, 3],\n",
    "        'info_locations': [\n",
    "            {'position': [1, 1], 'info_type': 'X', 'collection_order': 0},\n",
    "            {'position': [3, 0], 'info_type': 'Y', 'collection_order': 1},\n",
    "            {'position': [3, 2], 'info_type': 'Z', 'collection_order': 2},\n",
    "        ],\n",
    "        'ditches': [(1, 0), (2, 0), (1, 2)]\n",
    "    },\n",
    "    # Config 2\n",
    "    {\n",
    "        'init_positions': [[0, 0]],\n",
    "        'target_pos': [3, 3],\n",
    "        'info_locations': [\n",
    "            {'position': [1, 2], 'info_type': 'X', 'collection_order': 0},\n",
    "            {'position': [2, 1], 'info_type': 'Y', 'collection_order': 1},\n",
    "            {'position': [3, 1], 'info_type': 'Z', 'collection_order': 2},\n",
    "        ],\n",
    "        'ditches': [(0, 1), (1, 3), (2, 2)]\n",
    "    },\n",
    "    # Config 3\n",
    "    {\n",
    "        'init_positions': [[3, 3]],\n",
    "        'target_pos': [0, 0],\n",
    "        'info_locations': [\n",
    "            {'position': [0, 1], 'info_type': 'X', 'collection_order': 0},\n",
    "            {'position': [1, 3], 'info_type': 'Y', 'collection_order': 1},\n",
    "            {'position': [2, 0], 'info_type': 'Z', 'collection_order': 2},\n",
    "        ],\n",
    "        'ditches': [(1, 1), (2, 3), (3, 0)]\n",
    "    },\n",
    "    # Config 4\n",
    "    {\n",
    "        'init_positions': [[1, 0]],\n",
    "        'target_pos': [2, 3],\n",
    "        'info_locations': [\n",
    "            {'position': [0, 2], 'info_type': 'X', 'collection_order': 0},\n",
    "            {'position': [2, 2], 'info_type': 'Y', 'collection_order': 1},\n",
    "            {'position': [3, 0], 'info_type': 'Z', 'collection_order': 2},\n",
    "        ],\n",
    "        'ditches': [(0, 0), (1, 1), (3, 3)]\n",
    "    },\n",
    "    # Config 5\n",
    "    {\n",
    "        'init_positions': [[0, 3]],\n",
    "        'target_pos': [3, 0],\n",
    "        'info_locations': [\n",
    "            {'position': [1, 1], 'info_type': 'X', 'collection_order': 0},\n",
    "            {'position': [2, 3], 'info_type': 'Y', 'collection_order': 1},\n",
    "            {'position': [3, 2], 'info_type': 'Z', 'collection_order': 2},\n",
    "        ],\n",
    "        'ditches': [(0, 1), (2, 1), (3, 3)]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define agent configurations\n",
    "agent_types = [\n",
    "    {\n",
    "        \"name\": \"Baseline_Static\",\n",
    "        \"agent_class\": QLearningAgentFlat,\n",
    "        \"change_priorities\": None  # No changes\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"Baseline-Boost_Static\",\n",
    "        \"agent_class\": QLearningAgentFlat,\n",
    "        \"change_priorities\": None  # No changes\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"CA-MIQ_Static (Ours)\",\n",
    "        \"agent_class\": QLearningAgentMaxInfoRL,\n",
    "        \"change_priorities\": None  # No changes\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"Baseline_Dynamic\",\n",
    "        \"agent_class\": QLearningAgentFlat,\n",
    "        \"change_priorities\": {\n",
    "            1700: {'X': 2, 'Y': 0, 'Z': 1},  # Change from X-Y-Z to Y-Z-X\n",
    "            # 3500: {'X': 1, 'Y': 2, 'Z': 0},  # Change to Z-X-Y\n",
    "        }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"Baseline-Boost_Dynamic\",\n",
    "        \"agent_class\": QLearningAgentFlat,\n",
    "        \"change_priorities\": {\n",
    "            1700: {'X': 2, 'Y': 0, 'Z': 1},  # Change from X-Y-Z to Y-Z-X\n",
    "            # 3500: {'X': 1, 'Y': 2, 'Z': 0},  # Change to Z-X-Y\n",
    "        }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"CA-MIQ_Dynamic (Ours)\",\n",
    "        \"agent_class\": QLearningAgentMaxInfoRL,\n",
    "        \"change_priorities\": {\n",
    "            1700: {'X': 2, 'Y': 0, 'Z': 1},  # Change from X-Y-Z to Y-Z-X\n",
    "            # 3500: {'X': 1, 'Y': 2, 'Z': 0},  # Change to Z-X-Y\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010a25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "######   S    O    S   ######\n",
    "# Path to the results file   #### when extracting from the pickle file, use the path to the directory where the results are stored\n",
    "# Note: The path should be updated to the actual location of the results file\n",
    "log_dir = \"logs/multi_env_comparison_parallel_20250505_122847\"\n",
    "results_file = os.path.join(log_dir, \"all_results.pkl\")  #logs/multi_env_comparison_parallel_20250505_122847/all_results.pkl\n",
    "\n",
    "# Load the pickle file\n",
    "with open(results_file, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "######   S    O    S   ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_visualizations(all_results, agent_types, env_configs, log_dir):\n",
    "    \"\"\"Generate comprehensive visualizations summarizing the experiment results.\"\"\"\n",
    "    # Create visualization directory\n",
    "    vis_dir = os.path.join(log_dir, \"visualizations\")\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "    \n",
    "    # Organize data by agent type\n",
    "    agent_data = {agent[\"name\"]: {\"rewards\": [], \"steps\": [], \"metrics\": []} for agent in agent_types}\n",
    "    \n",
    "    # Group results by environment config\n",
    "    env_results = {i: {\"agent_performance\": {}} for i in range(len(env_configs))}\n",
    "    \n",
    "    # Extract data from all trials\n",
    "    for trial, data in all_results.items():\n",
    "        config_idx = data[\"config_idx\"]\n",
    "        \n",
    "        for agent_name, agent_result in data[\"results\"].items():\n",
    "            # Store raw rewards and steps data\n",
    "            agent_data[agent_name][\"rewards\"].append(agent_result[\"rewards\"])\n",
    "            agent_data[agent_name][\"steps\"].append(agent_result[\"steps\"])\n",
    "            \n",
    "            # Store metrics\n",
    "            if \"metrics\" in agent_result:\n",
    "                agent_data[agent_name][\"metrics\"].append(agent_result[\"metrics\"])\n",
    "            \n",
    "            # Store performance by environment\n",
    "            if agent_name not in env_results[config_idx][\"agent_performance\"]:\n",
    "                env_results[config_idx][\"agent_performance\"][agent_name] = []\n",
    "            \n",
    "            # Use last 100 episodes as final performance measure\n",
    "            last_100_rewards = agent_result[\"rewards\"][-100:]\n",
    "            env_results[config_idx][\"agent_performance\"][agent_name].append(np.mean(last_100_rewards))\n",
    "    \n",
    "    # 1. Overall Agent Performance Summary (average across all environments)\n",
    "    print(\"\\nAgent Performance Summary (across all environments):\")\n",
    "    for agent_name, data in agent_data.items():\n",
    "        # Calculate average of last 100 episodes for each trial\n",
    "        final_performances = []\n",
    "        for reward_history in data[\"rewards\"]:\n",
    "            final_performances.append(np.mean(reward_history[-100:]))\n",
    "        \n",
    "        avg_performance = np.mean(final_performances)\n",
    "        std_performance = np.std(final_performances)\n",
    "        print(f\"Agent {agent_name}: {avg_performance:.2f} ± {std_performance:.2f}\")\n",
    "    \n",
    "    # 2. Create comparison chart for overall performance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot bars for each agent\n",
    "    agent_names = list(agent_data.keys())\n",
    "    x_pos = np.arange(len(agent_names))\n",
    "    \n",
    "    for i, agent_name in enumerate(agent_names):\n",
    "        # Calculate average of last 100 episodes for each trial\n",
    "        final_performances = []\n",
    "        for reward_history in agent_data[agent_name][\"rewards\"]:\n",
    "            final_performances.append(np.mean(reward_history[-100:]))\n",
    "        \n",
    "        plt.bar(x_pos[i], np.mean(final_performances), \n",
    "                yerr=np.std(final_performances), \n",
    "                capsize=10, \n",
    "                label=agent_name)\n",
    "    \n",
    "    plt.title(\"Average Agent Performance Across All Environment Configurations\")\n",
    "    plt.ylabel(\"Average Reward (Last 100 Episodes)\")\n",
    "    plt.xticks(x_pos, agent_names, rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(vis_dir, \"overall_agent_comparison.png\"))\n",
    "    \n",
    "    # 3. Static vs Dynamic Agent Comparison\n",
    "    window_size = 15  # For smoothing\n",
    "    \n",
    "    # 3.1 Static environment agents\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    for agent_name, data in agent_data.items():\n",
    "        if \"Static\" in agent_name:  # Only include static agents\n",
    "            # Average rewards across all trials\n",
    "            avg_rewards = np.mean(data[\"rewards\"], axis=0)\n",
    "            \n",
    "            # Smooth rewards using moving average\n",
    "            smoothed_rewards = np.convolve(avg_rewards, np.ones(window_size)/window_size, mode='valid')\n",
    "            plt.plot(smoothed_rewards, label=agent_name)\n",
    "            \n",
    "            # Calculate confidence intervals\n",
    "            all_smoothed = []\n",
    "            for reward_history in data[\"rewards\"]:\n",
    "                run_smoothed = np.convolve(reward_history, np.ones(window_size)/window_size, mode='valid')\n",
    "                all_smoothed.append(run_smoothed)\n",
    "            \n",
    "            all_smoothed = np.array(all_smoothed)\n",
    "            std_dev = np.std(all_smoothed, axis=0)\n",
    "            \n",
    "            # Plot confidence interval (±1 std dev)\n",
    "            x = np.arange(len(smoothed_rewards))\n",
    "            plt.fill_between(x, smoothed_rewards - std_dev, smoothed_rewards + std_dev, alpha=0.2)\n",
    "    \n",
    "    plt.title('Learning Curves (w/o Priority Shift)')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Average Reward (Smoothed)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(vis_dir, 'reward_trends_static.png'))\n",
    "    \n",
    "    # 3.2 Dynamic environment agents\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    dynamic_smoothed_rewards = {}  # Store for min/max calculation\n",
    "    \n",
    "    for agent_name, data in agent_data.items():\n",
    "        if \"Dynamic\" in agent_name:  # Only include dynamic agents\n",
    "            # Average rewards across all trials\n",
    "            avg_rewards = np.mean(data[\"rewards\"], axis=0)\n",
    "            \n",
    "            # Smooth rewards using moving average\n",
    "            smoothed_rewards = np.convolve(avg_rewards, np.ones(window_size)/window_size, mode='valid')\n",
    "            plt.plot(smoothed_rewards, label=agent_name)\n",
    "            dynamic_smoothed_rewards[agent_name] = smoothed_rewards\n",
    "            \n",
    "            # Calculate confidence intervals\n",
    "            all_smoothed = []\n",
    "            for reward_history in data[\"rewards\"]:\n",
    "                run_smoothed = np.convolve(reward_history, np.ones(window_size)/window_size, mode='valid')\n",
    "                all_smoothed.append(run_smoothed)\n",
    "            \n",
    "            all_smoothed = np.array(all_smoothed)\n",
    "            std_dev = np.std(all_smoothed, axis=0)\n",
    "            \n",
    "            # Plot confidence interval (±1 std dev)\n",
    "            x = np.arange(len(smoothed_rewards))\n",
    "            plt.fill_between(x, smoothed_rewards - std_dev, smoothed_rewards + std_dev, alpha=0.2)\n",
    "    \n",
    "    # Add priority change markers (if we have data for dynamic agents)\n",
    "    if dynamic_smoothed_rewards:\n",
    "        # Calculate global min/max for consistent text placement\n",
    "        all_rewards = np.concatenate(list(dynamic_smoothed_rewards.values()))\n",
    "        min_reward = np.min(all_rewards)\n",
    "        max_reward = np.max(all_rewards)\n",
    "        \n",
    "        # Get the change priority episodes from one of the dynamic agents\n",
    "        for agent in agent_types:\n",
    "            if agent[\"change_priorities\"] is not None:\n",
    "                for episode in agent[\"change_priorities\"].keys():\n",
    "                    if episode >= window_size//2:\n",
    "                        adjusted_episode = episode - window_size//2\n",
    "                        \n",
    "                        bullet_y = max_reward + (max_reward - min_reward) * 0.05  # Slightly above highest reward\n",
    "                        plt.plot(adjusted_episode, \n",
    "                                bullet_y, \n",
    "                                marker='o', \n",
    "                                markersize=10, \n",
    "                                color='red', \n",
    "                                label='Priority Change' if episode == list(agent[\"change_priorities\"].keys())[0] else \"\")\n",
    "                break  # Only need one agent's change points as they're the same\n",
    "    \n",
    "    plt.title('Learning Curves (with 1 Priority Shift)')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Average Reward (Smoothed)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(vis_dir, 'reward_trends_dynamic.png'))\n",
    "    \n",
    "    # 4. Performance by Environment Configuration\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Setup\n",
    "    env_labels = [f\"Config {i+1}\" for i in range(len(env_configs))]\n",
    "    agent_names = list(agent_data.keys())\n",
    "    x = np.arange(len(env_labels))\n",
    "    width = 0.2  # width of the bars\n",
    "    \n",
    "    # Plot bars for each agent grouped by environment\n",
    "    for i, agent_name in enumerate(agent_names):\n",
    "        # Collect performance across environments\n",
    "        env_perf = []\n",
    "        env_std = []\n",
    "        \n",
    "        for env_idx in range(len(env_configs)):\n",
    "            if agent_name in env_results[env_idx][\"agent_performance\"]:\n",
    "                perf_values = env_results[env_idx][\"agent_performance\"][agent_name]\n",
    "                if perf_values:\n",
    "                    env_perf.append(np.mean(perf_values))\n",
    "                    env_std.append(np.std(perf_values))\n",
    "                else:\n",
    "                    env_perf.append(0)\n",
    "                    env_std.append(0)\n",
    "            else:\n",
    "                env_perf.append(0)\n",
    "                env_std.append(0)\n",
    "        \n",
    "        # Calculate the offset for this agent's bars\n",
    "        offset = width * (i - len(agent_names)/2 + 0.5)\n",
    "        \n",
    "        # Plot with error bars\n",
    "        plt.bar(x + offset, env_perf, width, label=agent_name, yerr=env_std, capsize=5)\n",
    "    \n",
    "    plt.title('Agent Performance by Environment Configuration')\n",
    "    plt.xlabel('Environment')\n",
    "    plt.ylabel('Average Final Reward')\n",
    "    plt.xticks(x, env_labels)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(agent_names))\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(vis_dir, 'performance_by_environment.png'))\n",
    "\n",
    "    \n",
    "    # Replace section 5 in generate_summary_visualizations with this enhanced adaptation metrics analysis\n",
    "\n",
    "    # 5. Enhanced Adaptation Metrics Analysis\n",
    "    # Collect adaptation metrics if available\n",
    "    adaptation_metrics = {agent_name: [] for agent_name in agent_names if \"Dynamic\" in agent_name}\n",
    "\n",
    "    print(\"\\nProcessing adaptation metrics for analysis...\")\n",
    "    for agent_name in adaptation_metrics.keys():\n",
    "        for metrics_list in agent_data[agent_name][\"metrics\"]:\n",
    "            # Check both possible fields where the priority changes might be stored\n",
    "            if \"priority_changes\" in metrics_list:\n",
    "                adaptation_metrics[agent_name].append(metrics_list[\"priority_changes\"])\n",
    "            elif \"all_priority_changes\" in metrics_list:\n",
    "                # Alternative field from our updated agent\n",
    "                processed_changes = []\n",
    "                for change in metrics_list[\"all_priority_changes\"]:\n",
    "                    # Convert raw change data to the expected format\n",
    "                    processed_change = {\n",
    "                        'episode': change.get('episode', 0),\n",
    "                        'completed': change.get('adaptation_completed', False),\n",
    "                        'success_rate_before': change.get('success_rate_before', 0),\n",
    "                    }\n",
    "                    \n",
    "                    if change.get('adaptation_completed', False):\n",
    "                        processed_change.update({\n",
    "                            'steps_to_adapt': change.get('steps_to_adapt', 0),\n",
    "                            'episodes_to_adapt': change.get('episodes_to_adapt', 0),\n",
    "                            'success_rate_after': change.get('success_rate_after', 0)\n",
    "                        })\n",
    "                    else:\n",
    "                        # For incomplete adaptations\n",
    "                        processed_change.update({\n",
    "                            'steps_without_recovery': change.get('steps_without_recovery', 0),\n",
    "                            'episodes_without_recovery': change.get('episodes_without_recovery', 0)\n",
    "                        })\n",
    "                    \n",
    "                    processed_changes.append(processed_change)\n",
    "                \n",
    "                adaptation_metrics[agent_name].append(processed_changes)\n",
    "\n",
    "    # If we have adaptation metrics, create enhanced visualizations\n",
    "    if any(metrics for metrics in adaptation_metrics.values()):\n",
    "        print(f\"Found adaptation metrics, creating visualizations...\")\n",
    "        \n",
    "        # Find max number of changes\n",
    "        max_changes = 0\n",
    "        for metrics_list in adaptation_metrics.values():\n",
    "            for run_metrics in metrics_list:\n",
    "                max_changes = max(max_changes, len(run_metrics))\n",
    "        \n",
    "        if max_changes > 0:\n",
    "            print(f\"Found {max_changes} priority changes to analyze\")\n",
    "            \n",
    "            # Setup\n",
    "            labels = [f\"Change {i+1}\" for i in range(max_changes)]\n",
    "            x = np.arange(len(labels))\n",
    "            width = 0.35 / len(adaptation_metrics)\n",
    "            \n",
    "            # 5.1 Episodes to Adapt Analysis\n",
    "            plt.figure(figsize=(14, 12))\n",
    "            plt.subplot(3, 1, 1)\n",
    "            \n",
    "            # Plot episodes to adapt for each agent\n",
    "            for i, (agent_name, metrics_list) in enumerate(adaptation_metrics.items()):\n",
    "                # Calculate average episodes to adapt for each change\n",
    "                avg_episodes = []\n",
    "                std_episodes = []\n",
    "                \n",
    "                for change_idx in range(max_changes):\n",
    "                    episode_values = []\n",
    "                    \n",
    "                    for run_metrics in metrics_list:\n",
    "                        if change_idx < len(run_metrics):\n",
    "                            change = run_metrics[change_idx]\n",
    "                            if change.get('completed', False) and 'episodes_to_adapt' in change:\n",
    "                                episode_values.append(change['episodes_to_adapt'])\n",
    "                    \n",
    "                    if episode_values:\n",
    "                        avg_episodes.append(np.mean(episode_values))\n",
    "                        std_episodes.append(np.std(episode_values))\n",
    "                    else:\n",
    "                        avg_episodes.append(0)\n",
    "                        std_episodes.append(0)\n",
    "                \n",
    "                # Plot with offset for each agent\n",
    "                offset = width * (i - len(adaptation_metrics)/2 + 0.5)\n",
    "                plt.bar(x + offset, avg_episodes, width, label=agent_name, yerr=std_episodes, capsize=5)\n",
    "            \n",
    "            plt.ylabel('Episodes to Adapt')\n",
    "            plt.title('Number of Episodes Required to Adapt After Priority Changes')\n",
    "            plt.xticks(x, labels)\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # 5.2 Steps to Adapt Analysis (original plot)\n",
    "            plt.subplot(3, 1, 2)\n",
    "            \n",
    "            # Plot steps to adapt for each agent\n",
    "            for i, (agent_name, metrics_list) in enumerate(adaptation_metrics.items()):\n",
    "                # Calculate average steps to adapt for each change\n",
    "                avg_steps = []\n",
    "                std_steps = []\n",
    "                \n",
    "                for change_idx in range(max_changes):\n",
    "                    steps_values = []\n",
    "                    \n",
    "                    for run_metrics in metrics_list:\n",
    "                        if change_idx < len(run_metrics):\n",
    "                            change = run_metrics[change_idx]\n",
    "                            if change.get('completed', False) and 'steps_to_adapt' in change:\n",
    "                                steps_values.append(change['steps_to_adapt'])\n",
    "                    \n",
    "                    if steps_values:\n",
    "                        avg_steps.append(np.mean(steps_values))\n",
    "                        std_steps.append(np.std(steps_values))\n",
    "                    else:\n",
    "                        avg_steps.append(0)\n",
    "                        std_steps.append(0)\n",
    "                \n",
    "                # Plot with offset for each agent\n",
    "                offset = width * (i - len(adaptation_metrics)/2 + 0.5)\n",
    "                plt.bar(x + offset, avg_steps, width, label=agent_name, yerr=std_steps, capsize=5)\n",
    "            \n",
    "            plt.ylabel('Steps to Adapt')\n",
    "            plt.title('Total Environment Steps Required to Adapt After Priority Changes')\n",
    "            plt.xticks(x, labels)\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # 5.3 Success Rate Improvement\n",
    "            plt.subplot(3, 1, 3)\n",
    "            \n",
    "            # Plot success rate improvement for each agent\n",
    "            for i, (agent_name, metrics_list) in enumerate(adaptation_metrics.items()):\n",
    "                # Calculate success rate improvement for each change\n",
    "                avg_improvement = []\n",
    "                std_improvement = []\n",
    "                \n",
    "                for change_idx in range(max_changes):\n",
    "                    improvement_values = []\n",
    "                    \n",
    "                    for run_metrics in metrics_list:\n",
    "                        if change_idx < len(run_metrics):\n",
    "                            change = run_metrics[change_idx]\n",
    "                            if change.get('completed', False) and 'success_rate_before' in change and 'success_rate_after' in change:\n",
    "                                improvement = change['success_rate_after'] - change['success_rate_before']\n",
    "                                improvement_values.append(improvement)\n",
    "                    \n",
    "                    if improvement_values:\n",
    "                        avg_improvement.append(np.mean(improvement_values))\n",
    "                        std_improvement.append(np.std(improvement_values))\n",
    "                    else:\n",
    "                        avg_improvement.append(0)\n",
    "                        std_improvement.append(0)\n",
    "                \n",
    "                # Plot with offset for each agent\n",
    "                offset = width * (i - len(adaptation_metrics)/2 + 0.5)\n",
    "                plt.bar(x + offset, avg_improvement, width, label=agent_name, yerr=std_improvement, capsize=5)\n",
    "            \n",
    "            plt.ylabel('Success Rate Improvement (%)')\n",
    "            plt.title('Performance Improvement After Adaptation')\n",
    "            plt.xticks(x, labels)\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(vis_dir, 'adaptation_metrics.png'))\n",
    "            \n",
    "            # 5.4 Adaptation Success Rate Analysis\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            # Create a matrix of adaptation success rates for each agent and change\n",
    "            for i, (agent_name, metrics_list) in enumerate(adaptation_metrics.items()):\n",
    "                # Calculate success rate for each change\n",
    "                success_rates = []\n",
    "                \n",
    "                for change_idx in range(max_changes):\n",
    "                    total_runs = 0\n",
    "                    success_count = 0\n",
    "                    \n",
    "                    for run_metrics in metrics_list:\n",
    "                        if change_idx < len(run_metrics):\n",
    "                            total_runs += 1\n",
    "                            change = run_metrics[change_idx]\n",
    "                            if change.get('completed', False):\n",
    "                                success_count += 1\n",
    "                    \n",
    "                    if total_runs > 0:\n",
    "                        success_rates.append((success_count / total_runs) * 100)\n",
    "                    else:\n",
    "                        success_rates.append(0)\n",
    "                \n",
    "                # Plot with offset for each agent\n",
    "                offset = width * (i - len(adaptation_metrics)/2 + 0.5)\n",
    "                plt.bar(x + offset, success_rates, width, label=agent_name)\n",
    "            \n",
    "            plt.ylabel('Adaptation Success Rate (%)')\n",
    "            plt.title('Percentage of Runs Where Agent Successfully Adapted')\n",
    "            plt.xticks(x, labels)\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3, axis='y')\n",
    "            plt.savefig(os.path.join(vis_dir, 'adaptation_success_rates.png'))\n",
    "            \n",
    "            # 5.5 Adaptation Time Comparison\n",
    "            plt.figure(figsize=(14, 10))\n",
    "            \n",
    "            # First subplot: Recovery time in episodes\n",
    "            plt.subplot(2, 1, 1)\n",
    "            \n",
    "            # For each agent, create a box plot of episodes to adapt for each change\n",
    "            boxplot_data = []\n",
    "            agent_colors = plt.cm.tab10(np.linspace(0, 1, len(adaptation_metrics)))\n",
    "            \n",
    "            for agent_idx, (agent_name, metrics_list) in enumerate(adaptation_metrics.items()):\n",
    "                for change_idx in range(max_changes):\n",
    "                    episode_values = []\n",
    "                    \n",
    "                    for run_metrics in metrics_list:\n",
    "                        if change_idx < len(run_metrics):\n",
    "                            change = run_metrics[change_idx]\n",
    "                            if change.get('completed', False) and 'episodes_to_adapt' in change:\n",
    "                                episode_values.append(change['episodes_to_adapt'])\n",
    "                    \n",
    "                    if episode_values:\n",
    "                        boxplot_data.append({\n",
    "                            'label': f\"{agent_name}\\nChange {change_idx+1}\",\n",
    "                            'data': episode_values,\n",
    "                            'color': agent_colors[agent_idx]\n",
    "                        })\n",
    "            \n",
    "            if boxplot_data:\n",
    "                # Create box plots\n",
    "                boxes = plt.boxplot([item['data'] for item in boxplot_data], \n",
    "                                labels=[item['label'] for item in boxplot_data],\n",
    "                                patch_artist=True,\n",
    "                                showfliers=False)  # Hide outliers for clarity\n",
    "                \n",
    "                # Color boxes by agent\n",
    "                for box, item in zip(boxes['boxes'], boxplot_data):\n",
    "                    box.set(facecolor=item['color'])\n",
    "            \n",
    "            plt.ylabel('Episodes to Adapt')\n",
    "            plt.title('Distribution of Adaptation Time Across Runs (Episodes)')\n",
    "            plt.grid(True, alpha=0.3, axis='y')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            \n",
    "            # Second subplot: Recovery time in steps\n",
    "            plt.subplot(2, 1, 2)\n",
    "            \n",
    "            # For each agent, create a box plot of steps to adapt for each change\n",
    "            boxplot_data = []\n",
    "            \n",
    "            for agent_idx, (agent_name, metrics_list) in enumerate(adaptation_metrics.items()):\n",
    "                for change_idx in range(max_changes):\n",
    "                    step_values = []\n",
    "                    \n",
    "                    for run_metrics in metrics_list:\n",
    "                        if change_idx < len(run_metrics):\n",
    "                            change = run_metrics[change_idx]\n",
    "                            if change.get('completed', False) and 'steps_to_adapt' in change:\n",
    "                                step_values.append(change['steps_to_adapt'])\n",
    "                    \n",
    "                    if step_values:\n",
    "                        boxplot_data.append({\n",
    "                            'label': f\"{agent_name}\\nChange {change_idx+1}\",\n",
    "                            'data': step_values,\n",
    "                            'color': agent_colors[agent_idx]\n",
    "                        })\n",
    "            \n",
    "            if boxplot_data:\n",
    "                # Create box plots\n",
    "                boxes = plt.boxplot([item['data'] for item in boxplot_data], \n",
    "                                labels=[item['label'] for item in boxplot_data],\n",
    "                                patch_artist=True,\n",
    "                                showfliers=False)  # Hide outliers for clarity\n",
    "                \n",
    "                # Color boxes by agent\n",
    "                for box, item in zip(boxes['boxes'], boxplot_data):\n",
    "                    box.set(facecolor=item['color'])\n",
    "            \n",
    "            plt.ylabel('Steps to Adapt')\n",
    "            plt.title('Distribution of Adaptation Time Across Runs (Steps)')\n",
    "            plt.grid(True, alpha=0.3, axis='y')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(vis_dir, 'adaptation_time_distributions.png'))\n",
    "            \n",
    "            # 5.6 Print Detailed Adaptation Summary Table\n",
    "            print(\"\\n\" + \"=\"*100)\n",
    "            print(\"ADAPTATION METRICS SUMMARY\")\n",
    "            print(\"=\"*100)\n",
    "            \n",
    "            header = f\"{'Agent':<20} | {'Change':<10} | {'Success Rate':<15} | {'Avg Episodes':<15} | {'Avg Steps':<15} | {'Improvement':<15}\"\n",
    "            print(header)\n",
    "            print(\"=\"*100)\n",
    "            \n",
    "            for agent_name, metrics_list in adaptation_metrics.items():\n",
    "                for change_idx in range(max_changes):\n",
    "                    # Calculate metrics for this change and agent\n",
    "                    success_count = 0\n",
    "                    total_runs = 0\n",
    "                    episode_values = []\n",
    "                    step_values = []\n",
    "                    improvement_values = []\n",
    "                    \n",
    "                    for run_metrics in metrics_list:\n",
    "                        if change_idx < len(run_metrics):\n",
    "                            total_runs += 1\n",
    "                            change = run_metrics[change_idx]\n",
    "                            \n",
    "                            if change.get('completed', False):\n",
    "                                success_count += 1\n",
    "                                \n",
    "                                if 'episodes_to_adapt' in change:\n",
    "                                    episode_values.append(change['episodes_to_adapt'])\n",
    "                                \n",
    "                                if 'steps_to_adapt' in change:\n",
    "                                    step_values.append(change['steps_to_adapt'])\n",
    "                                \n",
    "                                if 'success_rate_before' in change and 'success_rate_after' in change:\n",
    "                                    improvement = change['success_rate_after'] - change['success_rate_before']\n",
    "                                    improvement_values.append(improvement)\n",
    "                    \n",
    "                    # Calculate statistics\n",
    "                    if total_runs > 0:\n",
    "                        success_rate = f\"{(success_count / total_runs) * 100:.1f}%\"\n",
    "                    else:\n",
    "                        success_rate = \"N/A\"\n",
    "                    \n",
    "                    avg_episodes = f\"{np.mean(episode_values):.2f}\" if episode_values else \"N/A\"\n",
    "                    avg_steps = f\"{np.mean(step_values):.2f}\" if step_values else \"N/A\"\n",
    "                    avg_improvement = f\"{np.mean(improvement_values):.2f}%\" if improvement_values else \"N/A\"\n",
    "                    \n",
    "                    # Print row\n",
    "                    row = f\"{agent_name:<20} | {f'Change {change_idx+1}':<10} | {success_rate:<15} | {avg_episodes:<15} | {avg_steps:<15} | {avg_improvement:<15}\"\n",
    "                    print(row)\n",
    "            \n",
    "            # 5.7 Overall Adaptation Effectiveness Summary\n",
    "            print(\"\\n\" + \"=\"*100)\n",
    "            print(\"OVERALL ADAPTATION EFFECTIVENESS\")\n",
    "            print(\"=\"*100)\n",
    "            \n",
    "            for agent_name, metrics_list in adaptation_metrics.items():\n",
    "                # Calculate overall metrics across all changes\n",
    "                total_changes = 0\n",
    "                successful_adaptations = 0\n",
    "                total_episodes = []\n",
    "                total_steps = []\n",
    "                \n",
    "                for run_metrics in metrics_list:\n",
    "                    for change in run_metrics:\n",
    "                        total_changes += 1\n",
    "                        \n",
    "                        if change.get('completed', False):\n",
    "                            successful_adaptations += 1\n",
    "                            \n",
    "                            if 'episodes_to_adapt' in change:\n",
    "                                total_episodes.append(change['episodes_to_adapt'])\n",
    "                            \n",
    "                            if 'steps_to_adapt' in change:\n",
    "                                total_steps.append(change['steps_to_adapt'])\n",
    "                \n",
    "                # Calculate overall statistics\n",
    "                if total_changes > 0:\n",
    "                    overall_success_rate = (successful_adaptations / total_changes) * 100\n",
    "                    print(f\"\\nAgent: {agent_name}\")\n",
    "                    print(f\"  Total priority changes: {total_changes}\")\n",
    "                    print(f\"  Successfully adapted: {successful_adaptations} ({overall_success_rate:.1f}%)\")\n",
    "                    \n",
    "                    if successful_adaptations > 0:\n",
    "                        avg_episodes = np.mean(total_episodes) if total_episodes else \"N/A\"\n",
    "                        avg_steps = np.mean(total_steps) if total_steps else \"N/A\"\n",
    "                        print(f\"  Average episodes to adapt: {avg_episodes:.2f}\")\n",
    "                        print(f\"  Average steps to adapt: {avg_steps:.2f}\")\n",
    "                        \n",
    "                        # Calculate statistics by change type\n",
    "                        if max_changes > 1:\n",
    "                            print(\"\\n  Breakdown by change:\")\n",
    "                            for change_idx in range(max_changes):\n",
    "                                change_episodes = []\n",
    "                                change_steps = []\n",
    "                                change_success = 0\n",
    "                                change_total = 0\n",
    "                                \n",
    "                                for run_metrics in metrics_list:\n",
    "                                    if change_idx < len(run_metrics):\n",
    "                                        change_total += 1\n",
    "                                        change = run_metrics[change_idx]\n",
    "                                        \n",
    "                                        if change.get('completed', False):\n",
    "                                            change_success += 1\n",
    "                                            \n",
    "                                            if 'episodes_to_adapt' in change:\n",
    "                                                change_episodes.append(change['episodes_to_adapt'])\n",
    "                                            \n",
    "                                            if 'steps_to_adapt' in change:\n",
    "                                                change_steps.append(change['steps_to_adapt'])\n",
    "                                \n",
    "                                if change_total > 0:\n",
    "                                    change_success_rate = (change_success / change_total) * 100\n",
    "                                    avg_change_episodes = np.mean(change_episodes) if change_episodes else \"N/A\"\n",
    "                                    print(f\"    Change {change_idx+1}: {change_success_rate:.1f}% success rate, {avg_change_episodes:.2f} avg episodes\")\n",
    "    \n",
    "    # 6. Performance metrics comparison\n",
    "    # Define key metrics to compare\n",
    "    metrics_to_compare = [\n",
    "        'mission_success_rate', \n",
    "        'info_collection_success_rate',\n",
    "        'average_steps_per_episode',\n",
    "        'mission_success_no_collisions_rate'\n",
    "    ]\n",
    "    \n",
    "    metric_labels = {\n",
    "        'mission_success_rate': 'Mission Success (%)',\n",
    "        'info_collection_success_rate': 'Info Collection (%)',\n",
    "        'average_steps_per_episode': 'Avg Steps',\n",
    "        'mission_success_no_collisions_rate': 'Success Without Collisions (%)'\n",
    "    }\n",
    "    \n",
    "    # Check if we have these metrics\n",
    "    have_metrics = True\n",
    "    for agent_name, data in agent_data.items():\n",
    "        if not data[\"metrics\"] or not all(metric in data[\"metrics\"][0] for metric in metrics_to_compare):\n",
    "            have_metrics = False\n",
    "            break\n",
    "    \n",
    "    if have_metrics:\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        \n",
    "        # Setup\n",
    "        x = np.arange(len(metrics_to_compare))\n",
    "        width = 0.2  # width of the bars\n",
    "        \n",
    "        # Calculate average metrics for each agent\n",
    "        for i, agent_name in enumerate(agent_names):\n",
    "            # Collect all values for each metric\n",
    "            metric_values = []\n",
    "            metric_stds = []\n",
    "            \n",
    "            for metric in metrics_to_compare:\n",
    "                values = [m.get(metric, 0) for m in agent_data[agent_name][\"metrics\"]]\n",
    "                metric_values.append(np.mean(values))\n",
    "                metric_stds.append(np.std(values))\n",
    "            \n",
    "            # Calculate the offset for this agent's bars\n",
    "            offset = width * (i - len(agent_names)/2 + 0.5)\n",
    "            \n",
    "            # Plot with error bars\n",
    "            plt.bar(x + offset, metric_values, width, label=agent_name, yerr=metric_stds, capsize=5)\n",
    "        \n",
    "        plt.xlabel('Metrics')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Performance Metrics Comparison')\n",
    "        plt.xticks(x, [metric_labels[metric] for metric in metrics_to_compare])\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=len(agent_names))\n",
    "        plt.grid(True, alpha=0.3, axis='y')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(vis_dir, 'performance_metrics.png'))\n",
    "        \n",
    "        # Print summary table\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"PERFORMANCE COMPARISON SUMMARY (AVERAGED ACROSS ALL ENVIRONMENTS)\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        header = f\"{'Metric':<40} | \" + \" | \".join([f\"{name:<15}\" for name in agent_names])\n",
    "        print(header)\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        metrics_to_print = metrics_to_compare + ['average_reward_per_episode']\n",
    "        \n",
    "        for metric in metrics_to_print:\n",
    "            values = []\n",
    "            for agent_name in agent_names:\n",
    "                # Calculate average value across all trials\n",
    "                metric_values = [m.get(metric, 0) for m in agent_data[agent_name][\"metrics\"] if metric in m]\n",
    "                if metric_values:\n",
    "                    avg_value = np.mean(metric_values)\n",
    "                    values.append(f\"{avg_value:.2f}\")\n",
    "                else:\n",
    "                    values.append(\"N/A\")\n",
    "            \n",
    "            metric_name = metric_labels.get(metric, metric)\n",
    "            row = f\"{metric_name:<40} | \" + \" | \".join([f\"{val:<15}\" for val in values])\n",
    "            print(row)\n",
    "    \n",
    "    print(f\"\\nResults and visualizations saved to {log_dir}\")\n",
    "    return vis_dir\n",
    "generate_summary_visualizations(results, agent_types, env_configs, log_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
